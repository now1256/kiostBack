{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864894ec-e74e-4f53-8011-1168cba3722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e939cc-8f47-4712-8cb4-3967e8d1dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"주어진 사용자 질문을 `order`, `menu`, 또는 `etc` 중 하나로 분류하세요. 한 단어 이상으로 응답하지 마세요.\n",
    "\n",
    "<question>\n",
    "{input}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffe2e9-ea8e-427a-87b1-a02e28da7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | ChatOpenAI(temperature=0)| StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc0e211-714d-4cdc-9c88-ce7857d632c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "examples = [\n",
    "            {\n",
    "                \"input\": \"아메리카노 한잔 따뜻하게 주세요  \",\n",
    "                \"answer\":\n",
    "        \"\"\"{\"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"} \"\"\",\n",
    "            },\n",
    "            \n",
    "             {\n",
    "                \"input\": \"아메리카노 한잔 주세요  \",\n",
    "                \"answer\":\n",
    "        \"\"\"  음료의 온도를 선택해주세요 뜨거운것과 차가운 것이 있습니다 \"\"\",\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"input\": \"라떼 두잔  주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\" 음료의 온도를 선택해주세요 뜨거운것과 차가운 것이 있습니다 \"\"\",\n",
    "            },\n",
    "            \n",
    "\n",
    "            {\n",
    "                \"input\": \"라떼 두잔 차갑게 주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\"{\"menu\": \"라떼\", \"amount\": \"2\", \"temperature\": \"ice\", \"action\": \"order\"}\"\"\",\n",
    "            },\n",
    "            \n",
    "            {\n",
    "                \"input\": \"아이스라떼 두잔 주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\"{\"menu\": \"라떼\", \"amount\": \"2\", \"temperature\": \"ice\", \"action\": \"order\"} \"\"\",\n",
    "            },\n",
    "    \n",
    "             {\n",
    "                \"input\": \"메뉴판 보여주세요.\",\n",
    "                \"answer\": \"\"\"\n",
    "        {\"action\": \"menu\"}\n",
    "        \"\"\",\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"input\": \"가게 메뉴 알려주세요.\",\n",
    "                \"answer\": \"\"\"\n",
    "        {\"action\": \"menu\"}\n",
    "        \"\"\",\n",
    "            },\n",
    "\n",
    "\n",
    "    \n",
    "        ]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    # output_parser = parser\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c55acd79-e02d-4caa-9ad9-643f641bf715",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_chain = (\n",
    "    final_prompt\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "\n",
    "\n",
    "order_chain = (\n",
    "    final_prompt\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    "    \n",
    ")\n",
    "\n",
    "general_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Respond to the following question concisely:\n",
    "\n",
    "Question: {input}\n",
    "Answer:\"\"\"\n",
    "    )\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7f07491-26aa-49b5-9f36-57ac452f4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"order\" in info[\"topic\"].lower():\n",
    "        return menu_chain\n",
    "    elif \"menu\" in info[\"topic\"].lower():\n",
    "        return order_chain\n",
    "    else:\n",
    "        return general_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3bd9c6f-c488-4f53-8f80-496582b0e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    # 주제에 \"수학\"이 포함되어 있는지 확인하고, 포함되어 있다면 math_chain을 실행합니다.\n",
    "    (lambda x: \"order\" in x[\"topic\"].lower(), menu_chain),\n",
    "    # 주제에 \"과학\"이 포함되어 있는지 확인하고, 포함되어 있다면 science_chain을 실행합니다.\n",
    "    (lambda x: \"menu\" in x[\"topic\"].lower(), order_chain),\n",
    "    # 위의 조건에 해당하지 않는 경우 general_chain을 실행합니다.\n",
    "    general_chain,\n",
    ")\n",
    "# 주제와 질문을 입력받아 branch를 실행하는 전체 체인을 정의합니다.\n",
    "full_chain = {\"topic\": chain,\n",
    "              \"input\": lambda x: x[\"input\"],} | branch | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6f53e9c-954a-46d2-a29c-c03fb9abb1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"action\": \"menu\"}'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"input\": \"메뉴보여주세요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "386e652f-55d5-491f-9f55-3bbe15d8e676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'음료의 온도를 선택해주세요 뜨거운것과 차가운 것이 있습니다'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"input\": \"라떼 한잔 주세요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0b89ce5-2f3c-46e3-bfcf-787f71ae26e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'메뉴에서 차가운 음료를 선택해주셔서 감사합니다. 주문이 완료되었습니다.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"input\": \"차가운걸로 주세요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad51af9a-6f63-49fe-8c0d-5a7ea982c032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"menu\": \"라떼\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"}'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"input\": \"라떼 아이스로 한잔 주세요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc073304-48a2-448b-9bdd-8a57f3bc70c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 좋은 날씨네요.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"input\": \"안녕하세요 오늘 날씨가 좋네요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3210ee-4ca6-4a44-9fc5-7632f4245b21",
   "metadata": {},
   "source": [
    "<h1>runnable memory</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c6011c7-6abb-474a-9c12-c9ffe422a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate,  MessagesPlaceholder\n",
    "examples = [\n",
    "            {\n",
    "                \"input\": \"아메리카노 한잔 따뜻하게 주세요  \",\n",
    "                \"answer\":\n",
    "        \"\"\"{\"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"} \"\"\",\n",
    "            },\n",
    "            \n",
    "             {\n",
    "                \"input\": \"아메리카노 한잔 주세요  \",\n",
    "                \"answer\":\n",
    "        \"\"\"  음료의 온도를 선택해주세요 뜨거운것과 차가운 것이 있습니다 \"\"\",\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"input\": \"라떼 두잔  주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\" 음료의 온도를 선택해주세요 뜨거운것과 차가운 것이 있습니다 \"\"\",\n",
    "            },\n",
    "            \n",
    "\n",
    "            {\n",
    "                \"input\": \"라떼 두잔 차갑게 주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\"{\"menu\": \"라떼\", \"amount\": \"2\", \"temperature\": \"ice\", \"action\": \"order\"}\"\"\",\n",
    "            },\n",
    "            \n",
    "            {\n",
    "                \"input\": \"아이스라떼 두잔 주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\"{\"menu\": \"라떼\", \"amount\": \"2\", \"temperature\": \"ice\", \"action\": \"order\"} \"\"\",\n",
    "            },\n",
    "    \n",
    "             {\n",
    "                \"input\": \"메뉴판 보여주세요.\",\n",
    "                \"answer\": \"\"\"\n",
    "        {\"action\": \"menu\"}\n",
    "        \"\"\",\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"input\": \"가게 메뉴 알려주세요.\",\n",
    "                \"answer\": \"\"\"\n",
    "        {\"action\": \"menu\"}\n",
    "        \"\"\",\n",
    "            },\n",
    "\n",
    "\n",
    "    \n",
    "        ]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    # output_parser = parser\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74d68aa-4732-4a63-b479-b0544b7092d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = final_prompt | ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059919fa-450d-4156-b29b-8472cbe89f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}  # 세션 기록을 저장할 딕셔너리\n",
    "\n",
    "\n",
    "# 세션 ID를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids: str) -> BaseChatMessageHistory:\n",
    "    print(session_ids)\n",
    "    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(  # RunnableWithMessageHistory 객체 생성\n",
    "        runnable,  # 실행할 Runnable 객체\n",
    "        get_session_history,  # 세션 기록을 가져오는 함수\n",
    "        input_messages_key=\"input\",  # 입력 메시지의 키\n",
    "        history_messages_key=\"history\",  # 기록 메시지의 키\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73ffc12-25d0-461a-9391-707a42465c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='음료의 온도를 선택해주세요 뜨거운것과 차가운 것이 있습니다', response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 344, 'total_tokens': 370}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    # 수학 관련 질문 \"코사인의 의미는 무엇인가요?\"를 입력으로 전달합니다.\n",
    "    {\"input\": \"아메리카노 한잔 주세요 \"},\n",
    "    # 설정 정보로 세션 ID \"abc123\"을 전달합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c474e59-9c33-4c29-a379-d9f0ebc26396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"hot\", \"action\": \"order\"}', response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 389, 'total_tokens': 419}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    # 수학 관련 질문 \"코사인의 의미는 무엇인가요?\"를 입력으로 전달합니다.\n",
    "    {\"input\": \"뜨거운걸로 주세요 \"},\n",
    "    # 설정 정보로 세션 ID \"abc123\"을 전달합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f49d23-46cd-4c96-9f95-d20f6f35e46e",
   "metadata": {},
   "source": [
    "<h1>API calling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979e6ff0-b211-41d9-9ea3-2d8aa90f9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_calling():\n",
    "    if parsed_json['action']=='order':\n",
    "        base_url = 'http://127.0.0.1:8000/users/menus/{}'\n",
    "        menu_name = parsed_json['menu']\n",
    "        url = base_url.format(menu_name)\n",
    "        response = requests.get(url)\n",
    "        # 응답 처리\n",
    "        print(response.status_code)  # 응답의 상태 코드 출력\n",
    "        print(response.json())  # JSON 형식의 응답 내용 출력\n",
    "        \n",
    "    if parsed_json['action'] == 'menu':\n",
    "        base_url = 'http://127.0.0.1:8000/users/menus'\n",
    "        response = requests.get(base_url)\n",
    "        print(response.status_code)  # 응답의 상태 코드 출력\n",
    "        print(response.json())  # JSON 형식의 응답 내용 출력\n",
    "\n",
    "    return response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
