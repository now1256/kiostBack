{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205094c8-b1c6-4a17-9de1-6c15f776f17c",
   "metadata": {},
   "source": [
    "<h1> split template_ tutorial </h1>\n",
    "RunnableBranch를 통해 template를 분리하고 사용자 지정 함수를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864894ec-e74e-4f53-8011-1168cba3722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc0e211-714d-4cdc-9c88-ce7857d632c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "examples = [\n",
    "            {\n",
    "                \"input\": \"아메리카노 한잔 따뜻하게 주세요  \",\n",
    "                \"answer\":\n",
    "        \"\"\"{\"id\":1, \"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\",\"action\": \"order\"} \"\"\",\n",
    "            },\n",
    "            \n",
    "             {\n",
    "                \"input\": \"아메리카노 한잔 주세요  \",\n",
    "                \"answer\":\n",
    "        \"\"\"{\"id\":1, \"menu\": \"아메리카노\", \"amount\": \"1\", \"action\": \"order\"} \"\"\",\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"input\": \"라떼 두잔  주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\"{\"id\":2,\"menu\": \"라떼\", \"amount\": \"2\", \"action\": \"order\"}\"\"\",\n",
    "            },\n",
    "            \n",
    "\n",
    "            {\n",
    "                \"input\": \"라떼 두잔 차갑게 주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\"{\"id\":2\", \"menu\": \"라떼\", \"amount\": \"2\", \"temperature\": \"ice\", \"action\": \"order\"}\"\"\",\n",
    "            },\n",
    "            \n",
    "            {\n",
    "                \"input\": \"아이스라떼 두잔 주세요  \",\n",
    "                \"answer\": \n",
    "        \"\"\"{\"id\":3\", menu\": \"라떼\", \"amount\": \"2\", \"temperature\": \"ice\", \"action\": \"order\"} \"\"\",\n",
    "            },\n",
    "    \n",
    "             {\n",
    "                \"input\": \"메뉴판 보여주세요.\",\n",
    "                \"answer\": \"\"\"\n",
    "        {\"action\": \"menu\"}\n",
    "        \"\"\",\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"input\": \"가게 메뉴 알려주세요.\",\n",
    "                \"answer\": \"\"\"\n",
    "        {\"action\": \"menu\"}\n",
    "        \"\"\",\n",
    "            },\n",
    "\n",
    "\n",
    "    \n",
    "        ]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    # output_parser = parser\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5042ec0-cbf5-455d-a0fa-c702a101b1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\"id\":1, \"menu\": \"아메리카노\", \"amount\": \"1\", \"action\": \"order\"}', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 354, 'total_tokens': 383}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = final_prompt | ChatOpenAI(temperature=0)\n",
    "\n",
    "chain.invoke({\"input\": \"아메리카노 한잔 주세요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee07e65-823e-4dbf-94e0-3454f1c048b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main \n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"주어진 사용자 질문을 `order`, `menu`, 또는 `etc` 중 하나로 분류하세요. \n",
    "<input>\n",
    "{input}\n",
    "</input>\n",
    "\n",
    "Classification:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54083cf4-4bdd-464d-87f8-6c7d90704a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_chain = (\n",
    "    final_prompt\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "\n",
    "order_chain = (\n",
    "    final_prompt\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "\n",
    "general_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Respond to the following question concisely:\n",
    "\n",
    "Question: {input}\n",
    "Answer:\"\"\"\n",
    "    )\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cf9f5d-df08-4ab2-a7c4-111ac4a9e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | ChatOpenAI(temperature=0)| StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3bd9c6f-c488-4f53-8f80-496582b0e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    # 주제에 \"수학\"이 포함되어 있는지 확인하고, 포함되어 있다면 math_chain을 실행합니다.\n",
    "    (lambda x: \"order\" in x[\"topic\"].lower(), menu_chain),\n",
    "    # 주제에 \"과학\"이 포함되어 있는지 확인하고, 포함되어 있다면 science_chain을 실행합니다.\n",
    "    (lambda x: \"menu\" in x[\"topic\"].lower(), order_chain),\n",
    "    # 위의 조건에 해당하지 않는 경우 general_chain을 실행합니다.\n",
    "    general_chain,\n",
    ")\n",
    "# 주제와 질문을 입력받아 branch를 실행하는 전체 체인을 정의합니다.\n",
    "full_chain = {\"topic\": chain,\n",
    "              \"input\": lambda x: x[\"input\"],} | branch | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f53e9c-954a-46d2-a29c-c03fb9abb1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"action\": \"menu\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"input\": \"메뉴보여주세요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad51af9a-6f63-49fe-8c0d-5a7ea982c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = full_chain.invoke({\"input\": \"아이스 아메리카노 한잔 주세요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc073304-48a2-448b-9bdd-8a57f3bc70c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 정말 좋네요.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"input\": \"안녕하세요 오늘 날씨가 좋네요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b05b7561-f479-4adf-8d92-d17f29a8c484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":1, \"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00870b72-cef8-453d-b99b-680edc412422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "def api_calling(input):\n",
    "    input = json.loads(input)\n",
    "    if input['action']=='order':\n",
    "        base_url = 'http://127.0.0.1:8000/users/menus/{}'\n",
    "        menu_name = input['id']\n",
    "        url = base_url.format(menu_name)\n",
    "        response = requests.get(url)\n",
    "        # 응답 처리\n",
    "        print(response.status_code)  # 응답의 상태 코드 출력\n",
    "        print(response.json())  # JSON 형식의 응답 내용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74d30e4d-8e52-4dc0-9ce0-6e53d1ae11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'id': 1, 'name': 'americano', 'price': 2000, 'temperature': True}\n"
     ]
    }
   ],
   "source": [
    "api_calling(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7238f-247a-47d9-adf6-68cf633f607c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
