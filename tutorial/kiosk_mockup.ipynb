{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65fc242c-39ae-493e-80b1-99f312d11489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c30c355b-8a16-4e8f-86e2-527265ceee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RealtimeSTT import AudioToTextRecorder\n",
    "import time\n",
    "import keyboard\n",
    "class S2T():\n",
    "    def __init__(self):\n",
    "        self.whisper_speech_to_text_model = \"medium\"\n",
    "\n",
    "    def speech_to_text(self):\n",
    "        recorder = AudioToTextRecorder(spinner=False, model=self.whisper_speech_to_text_model)\n",
    "        print(\"space를 눌러서 시작을 해주세요. \", end=\"\", flush=True)\n",
    "        keyboard.wait('space')\n",
    "        while keyboard.is_pressed('space'): pass\n",
    "        # Record from microphone until user presses space bar again\n",
    "        print(\"음성을 듣고있습니다 완료되면 space를 눌러주세요 .\\n\")\n",
    "        recorder.start()\n",
    "        while not keyboard.is_pressed('space'):\n",
    "            time.sleep(0.1)\n",
    "        user_text = recorder.stop().text()\n",
    "        return user_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc78d971-b342-4391-8e6a-188ced868aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS\n",
    "from RealtimeTTS import TextToAudioStream, OpenAIEngine, AzureEngine, ElevenlabsEngine\n",
    "\n",
    "class T2S():\n",
    "    def __init__(self):\n",
    "        self.engine= OpenAIEngine()  # 클래스 변수로 변경합니다.\n",
    "    def text_to_speack(self,input):\n",
    "        stream = TextToAudioStream(self.engine)\n",
    "        stream.feed(input)\n",
    "        return stream.play_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "259565b6-eb79-44a3-80f7-ae69e7664ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main chain 과 prompt \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"주어진 사용자 질문을 `order`, `menu`, 또는 `etc` 중 하나로 분류하세요. 한 단어 이상으로 응답하지 마세요.\n",
    "\n",
    "<question>\n",
    "{input}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\"\n",
    ")\n",
    "main_chain = prompt | ChatOpenAI(temperature=0)| StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d14455ab-3860-4b96-9e26-f9add5eee69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input': '아메리카노 한잔 따뜻하게 주세요  ', 'answer': '{\"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"}'}, {'input': '아메리카노 한잔 주세요  ', 'answer': '음료의 온도를 선택해주세요 뜨거운것과 차가운 것이 있습니다'}, {'input': '라떼 두잔  주세요  ', 'answer': '음료의 온도를 선택해주세요 뜨거운것과 차가운 것이 있습니다'}, {'input': '라떼 두잔 차갑게 주세요  ', 'answer': '{\"menu\": \"라떼\", \"amount\": \"2\", \"temperature\": \"ice\", \"action\": \"order\"}'}, {'input': '아이스라떼 두잔 주세요  ', 'answer': '{\"menu\": \"라떼\", \"amount\": \"2\", \"temperature\": \"ice\", \"action\": \"order\"} '}, {'input': '메뉴판 보여주세요.', 'answer': '{\"action\": \"menu\"}'}, {'input': '가게 메뉴 알려주세요.', 'answer': '{\"action\": \"menu\"}'}]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# YAML 파일을 UTF-8 인코딩으로 읽어옴\n",
    "with open('examples.yaml', 'r', encoding='utf-8') as file:\n",
    "    examples = yaml.safe_load(file)\n",
    "\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "271586cd-0d78-42bc-9205-c866089b0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# under_chain prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    # output_parser = parser\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\"\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6773ab69-840a-4361-a5be-7b3af503cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# under_chain 생성\n",
    "menu_chain = (\n",
    "    final_prompt\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "\n",
    "\n",
    "order_chain = (\n",
    "    final_prompt\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    "    \n",
    ")\n",
    "\n",
    "general_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Respond to the following question concisely:\n",
    "\n",
    "Question: {input}\n",
    "Answer:\"\"\"\n",
    "    )\n",
    "    # OpenAI의 LLM을 사용합니다.\n",
    "    | ChatOpenAI()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c0e80d3-4d00-4c9b-b6f2-e07e832f0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_chain과 under_chain의 결합 \n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    # 주제에 \"수학\"이 포함되어 있는지 확인하고, 포함되어 있다면 math_chain을 실행합니다.\n",
    "    (lambda x: \"order\" in x[\"topic\"].lower(), menu_chain),\n",
    "    # 주제에 \"과학\"이 포함되어 있는지 확인하고, 포함되어 있다면 science_chain을 실행합니다.\n",
    "    (lambda x: \"menu\" in x[\"topic\"].lower(), order_chain),\n",
    "    # 위의 조건에 해당하지 않는 경우 general_chain을 실행합니다.\n",
    "    general_chain,\n",
    ")\n",
    "# 주제와 질문을 입력받아 branch를 실행하는 전체 체인을 정의합니다.\n",
    "full_chain = {\"topic\": main_chain,\n",
    "              \"input\": lambda x: x[\"input\"],} | branch | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1fedec4-7ca5-4ca1-aa65-5436a663dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain과 memory 결합 \n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}  # 세션 기록을 저장할 딕셔너리\n",
    "\n",
    "\n",
    "# 세션 ID를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids: str) -> BaseChatMessageHistory:\n",
    "    print(session_ids)\n",
    "    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(  # RunnableWithMessageHistory 객체 생성\n",
    "        menu_chain,  # 실행할 Runnable 객체\n",
    "        get_session_history,  # 세션 기록을 가져오는 함수\n",
    "        input_messages_key=\"input\",  # 입력 메시지의 키\n",
    "        history_messages_key=\"history\",  # 기록 메시지의 키\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed734e06-046f-44e0-9222-740c7b89a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_message(text):\n",
    "    answer = with_message_history.invoke(\n",
    "        # 수학 관련 질문 \"코사인의 의미는 무엇인가요?\"를 입력으로 전달합니다.\n",
    "        {\"input\": text},\n",
    "        # 설정 정보로 세션 ID \"abc123\"을 전달합니다.\n",
    "        config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    "    ) \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8bdda6e-fab5-4c52-8d29-e2de6857ce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n",
      "content='{\"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"}' response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 430, 'total_tokens': 460}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "output = \"차가운걸로주세요.\"\n",
    "print(chat_message(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d74f012-27ba-4e7b-88c6-28ac562a9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "S2T = S2T()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e4f96-cc68-4311-a9e2-94c8b8c17dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 안녕하세요 커피 주문하려고 합니다\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n",
      "content='안녕하세요! 어떤 커피를 주문하시겠어요? 온도와 수량을 알려주시면 도와드리겠습니다.' response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 485, 'total_tokens': 534}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 아메리카노 한잔 주세요\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n",
      "content='음료의 온도를 선택해주세요. 뜨거운 것과 차가운 것이 있습니다.' response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 554, 'total_tokens': 581}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 아이스로 주세요 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n",
      "content='{\"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"}' response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 596, 'total_tokens': 626}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 메뉴 한번 보여주실래요?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n",
      "content='{\"action\": \"menu\"}' response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 648, 'total_tokens': 654}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 아이스 아메리카노 한잔이랑 뜨거운 라떼 한잔 주세요 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n",
      "content='{\"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"}\\n{\"menu\": \"라떼\", \"amount\": \"1\", \"temperature\": \"hot\", \"action\": \"order\"}' response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 694, 'total_tokens': 751}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 아이스아메리카노랑 라떼한잔 주세요\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n",
      "content='{\"menu\": \"아메리카노\", \"amount\": \"1\", \"temperature\": \"ice\", \"action\": \"order\"}\\n{\"menu\": \"라떼\", \"amount\": \"1\", \"temperature\": \"hot\", \"action\": \"order\"}' response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 781, 'total_tokens': 838}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    output = input()\n",
    "    print(chat_message(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a1334-6632-486d-8a5c-c8d345fa3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
